{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhaxNstHlmxrN/BGbWoqCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andreylive/UAV-human-detection/blob/main/Faster_R_CNN_for_UAV_human_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM1JmUCQLdKp"
      },
      "outputs": [],
      "source": [
        "# Install detectron 2\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqCNglJXRro5"
      },
      "outputs": [],
      "source": [
        "# Check installed libruaries\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIEKfPKFmW54"
      },
      "outputs": [],
      "source": [
        "# Install additonal libruaries and dataset\n",
        "\n",
        "# Common libruaries\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Dataset preparationand loading\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# Vizualization\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "# Configuration\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# Evaluation\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# Trainning\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grFIdy8ynP-7"
      },
      "outputs": [],
      "source": [
        "# Download HERIAL dataset\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"HD0OPLHEvjhSna3fqMZq\")\n",
        "project = rf.workspace(\"new-workspace-qsuag\").project(\"heridal-t428z\")\n",
        "dataset = project.version(2).download(\"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbI2PNEZF3sU"
      },
      "outputs": [],
      "source": [
        "# Register model\n",
        "DATA_SET_NAME = dataset.name.replace(\"-\", \"_\")+'2'\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\"\n",
        "\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR8ha4EHCkA-"
      },
      "outputs": [],
      "source": [
        "# Confirm custom dataset  registration\n",
        "[\n",
        "    data_set\n",
        "    for data_set\n",
        "    in MetadataCatalog.list()\n",
        "    if data_set.startswith(DATA_SET_NAME)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE0anblvMGJx"
      },
      "outputs": [],
      "source": [
        "# Vizialize images from the dataset\n",
        "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "\n",
        "dataset_entry = dataset_train[0]\n",
        "image = cv2.imread(dataset_entry[\"file_name\"])\n",
        "\n",
        "visualizer = Visualizer(\n",
        "    image[:, :, ::-1],\n",
        "    metadata=metadata, \n",
        "    scale=0.8, \n",
        "    instance_mode=ColorMode.IMAGE_BW\n",
        ")\n",
        "\n",
        "out = visualizer.draw_dataset_dict(dataset_entry)\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GavGRHy2M7Hb"
      },
      "source": [
        "## Train Model Using HERIDAL dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ3g-l56NMOY"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krCm2L_lNC83"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "ARCHITECTURE = \"faster_rcnn_R_101_FPN_3x\"\n",
        "CONFIG_FILE_PATH = f\"COCO-Detection/{ARCHITECTURE}.yaml\"\n",
        "MAX_ITER = 2000\n",
        "EVAL_PERIOD = 200\n",
        "BASE_LR = 0.001\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# OUTPUT DIR\n",
        "OUTPUT_DIR_PATH = os.path.join(\n",
        "    DATA_SET_NAME, \n",
        "    ARCHITECTURE, \n",
        "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxQU8JrgOD73"
      },
      "outputs": [],
      "source": [
        "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
        "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
        "cfg.DATASETS.TEST = (TRAIN_DATA_SET_NAME,) # Use train dataset for evaluation\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = BASE_LR\n",
        "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
        "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch-_5aCuXWj9"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S8y2W2AQvJq"
      },
      "outputs": [],
      "source": [
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XMPKQ28GRna"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $OUTPUT_DIR_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flInE1L-XTfx"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsByFDFbQwLi"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!ls"
      ],
      "metadata": {
        "id": "1Tubg0ekyKjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmAcBbpXX-Rh"
      },
      "outputs": [],
      "source": [
        "# Vizualize predctions\n",
        "dataset_valid = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "\n",
        "for d in dataset_valid:\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(img)\n",
        "    \n",
        "    visualizer = Visualizer(\n",
        "        img[:, :, ::-1],\n",
        "        metadata=metadata, \n",
        "        scale=0.8, \n",
        "        instance_mode=ColorMode.IMAGE_BW\n",
        "    )\n",
        "    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# Set the path to the saved model weights\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "\n",
        "# Set the testing score threshold\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "\n",
        "# Create the COCOEvaluator\n",
        "evaluator = COCOEvaluator(TRAIN_DATA_SET_NAME, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "\n",
        "# Build the test loader\n",
        "test_loader = build_detection_test_loader(cfg, TRAIN_DATA_SET_NAME)\n",
        "\n",
        "# Run the evaluation\n",
        "metrics = inference_on_dataset(predictor.model, test_loader, evaluator)"
      ],
      "metadata": {
        "id": "MHwqAqnX0UTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}